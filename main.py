# main.py
import io
import re
import unicodedata
from pathlib import Path

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st


# =========================
# Page / Global Style
# =========================
st.set_page_config(page_title="ğŸŒ± ê·¹ì§€ì‹ë¬¼ ìµœì  EC ë†ë„ ì—°êµ¬", layout="wide")

st.markdown(
    """
<style>
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR&display=swap');
html, body, [class*="css"] {
    font-family: 'Noto Sans KR', 'Malgun Gothic', sans-serif;
}
</style>
""",
    unsafe_allow_html=True,
)


def apply_plotly_korean_font(fig: go.Figure) -> go.Figure:
    fig.update_layout(
        font=dict(family="Malgun Gothic, Apple SD Gothic Neo, Noto Sans KR, sans-serif"),
        legend=dict(title=None),
        margin=dict(l=30, r=30, t=60, b=40),
    )
    return fig


# =========================
# Experiment constants
# =========================
SCHOOL_ORDER = ["ì†¡ë„ê³ ", "í•˜ëŠ˜ê³ ", "ì•„ë¼ê³ ", "ë™ì‚°ê³ "]
TARGET_EC_BY_SCHOOL = {
    "ì†¡ë„ê³ ": 1.0,
    "í•˜ëŠ˜ê³ ": 2.0,  # ìµœì 
    "ì•„ë¼ê³ ": 4.0,
    "ë™ì‚°ê³ ": 8.0,
}
COLOR_BY_SCHOOL = {
    "ì†¡ë„ê³ ": "#2E86AB",
    "í•˜ëŠ˜ê³ ": "#F39C12",  # ìµœì  ê°•ì¡°
    "ì•„ë¼ê³ ": "#27AE60",
    "ë™ì‚°ê³ ": "#8E44AD",
}
OPTIMAL_EC = 2.0


# =========================
# Robust path & filename (NFC/NFD safe)
# =========================
def get_data_dir() -> Path:
    """
    Streamlit Cloud/ë¡œì»¬ì—ì„œ data í´ë”ë¥¼ í™•ì‹¤íˆ ì°¾ëŠ”ë‹¤.
    - main.py ìœ„ì¹˜ ê¸°ì¤€ ./data ìš°ì„ 
    - ê·¸ ë‹¤ìŒ í˜„ì¬ ì‘ì—…í´ë” ./data
    """
    here = Path(__file__).resolve().parent
    cand1 = here / "data"
    if cand1.exists():
        return cand1

    cand2 = Path.cwd() / "data"
    if cand2.exists():
        return cand2

    return cand1  # ê¸°ë³¸


def _norm_all(s: str) -> set[str]:
    return {
        unicodedata.normalize("NFC", s),
        unicodedata.normalize("NFD", s),
    }


def canonical_filename(name: str) -> str:
    """
    ë¹„êµìš© í‘œì¤€í™”:
    - NFC ì •ê·œí™”
    - ê³µë°± ì œê±°
    - ì¤‘ë³µ í™•ì¥ì ë³´ì •(.csv.csv / .xlsx.xlsx)
    """
    n = unicodedata.normalize("NFC", str(name)).strip()
    low = n.lower()
    if low.endswith(".csv.csv"):
        n = n[:-4]  # ë§ˆì§€ë§‰ ".csv" ì œê±°
    if low.endswith(".xlsx.xlsx"):
        n = n[:-5]  # ë§ˆì§€ë§‰ ".xlsx" ì œê±°
    return n


def filename_match(candidate: str, desired: str) -> bool:
    c_nfc = canonical_filename(candidate)
    d_nfc = canonical_filename(desired)

    c_nfd = unicodedata.normalize("NFD", c_nfc)
    d_nfd = unicodedata.normalize("NFD", d_nfc)

    # ì™„ì „ì¼ì¹˜
    if c_nfc == d_nfc or c_nfd == d_nfd:
        return True
    # endswith í—ˆìš© (ì¤‘ë³µ í™•ì¥ì/ê²½ë¡œì°¨ í¡ìˆ˜)
    if c_nfc.endswith(d_nfc) or c_nfd.endswith(d_nfd):
        return True
    return False


def find_file_by_name(directory: Path, desired_name: str) -> Path | None:
    """
    pathlib.Path.iterdir()ë¡œë§Œ íƒìƒ‰í•˜ë©°,
    NFC/NFD ì–‘ë°©í–¥ ë¹„êµ + ì¤‘ë³µí™•ì¥ì/endswithê¹Œì§€ í¡ìˆ˜.
    """
    if not directory.exists():
        return None

    # desiredë„ NFC/NFD setë¡œ í•œë²ˆ ë” ì•ˆì „í•˜ê²Œ
    desired_norms = _norm_all(canonical_filename(desired_name))

    for p in directory.iterdir():
        if not p.is_file():
            continue

        cand_name = canonical_filename(p.name)
        cand_norms = _norm_all(cand_name)

        # 1) NFC/NFD êµì§‘í•©(ì™„ì „ì¼ì¹˜ê¸‰)
        if desired_norms.intersection(cand_norms):
            return p

        # 2) ë³´ê°• ë§¤ì¹­
        if filename_match(p.name, desired_name):
            return p

    return None


# =========================
# CSV read & column standardization
# =========================
def read_csv_safely(path: Path) -> pd.DataFrame:
    """
    í•œê¸€ CSV ì¸ì½”ë”© ì´ìŠˆ ë°©ì§€:
    utf-8-sig -> utf-8 -> cp949 -> euc-kr ìˆœìœ¼ë¡œ ì‹œë„
    """
    encodings = ["utf-8-sig", "utf-8", "cp949", "euc-kr"]
    last_err = None
    for enc in encodings:
        try:
            return pd.read_csv(path, encoding=enc)
        except Exception as e:
            last_err = e
    raise last_err


def normalize_colname(c: str) -> str:
    """
    ì»¬ëŸ¼ëª… ì •ê·œí™”:
    - BOM ì œê±°
    - ì†Œë¬¸ì
    - ê³µë°± ì œê±°
    - ê¸°í˜¸ ìµœì†Œí™”
    """
    c = unicodedata.normalize("NFC", str(c)).strip().lower()
    c = c.replace("\ufeff", "")
    c = re.sub(r"\s+", "", c)
    c = c.replace("-", "").replace(".", "")
    return c


def standardize_env_columns(df: pd.DataFrame) -> pd.DataFrame:
    """
    ì»¬ëŸ¼ëª…ì´ ì‚´ì§ ë‹¬ë¼ë„ time/temperature/humidity/ph/ecë¡œ ìë™ ì •ë¦¬
    """
    df2 = df.copy()
    colmap = {c: normalize_colname(c) for c in df2.columns}
    inv = {}
    for orig, n in colmap.items():
        inv.setdefault(n, []).append(orig)

    target = {
        "time": {"time", "datetime", "timestamp", "ì¸¡ì •ì‹œê°„", "ì‹œê°„", "date", "ë‚ ì§œ"},
        "temperature": {"temperature", "temp", "t", "ì˜¨ë„"},
        "humidity": {"humidity", "hum", "h", "ìŠµë„"},
        "ph": {"ph", "ì‚°ë„"},
        "ec": {"ec", "ì „ê¸°ì „ë„ë„"},
    }

    rename = {}
    for std, cands in target.items():
        found = None
        for cand in cands:
            if cand in inv:
                found = inv[cand][0]
                break
        if found is not None:
            rename[found] = std

    return df2.rename(columns=rename)


def ensure_datetime(df: pd.DataFrame, time_col: str) -> pd.DataFrame:
    out = df.copy()
    out[time_col] = pd.to_datetime(out[time_col], errors="coerce")
    out = out.dropna(subset=[time_col])
    return out.sort_values(time_col)


# =========================
# Growth helpers
# =========================
def pick_col(df: pd.DataFrame, candidates: list[str]) -> str | None:
    cols = list(df.columns)
    norm_map = {unicodedata.normalize("NFC", str(c)): c for c in cols}
    for cand in candidates:
        cand_nfc = unicodedata.normalize("NFC", cand)
        if cand_nfc in norm_map:
            return norm_map[cand_nfc]
    return None


# =========================
# Data loading (cached)
# =========================
@st.cache_data(show_spinner=False)
def load_environment_data(data_dir: Path) -> dict[str, pd.DataFrame]:
    env = {}
    desired_files = {
        "ì†¡ë„ê³ ": "ì†¡ë„ê³ _í™˜ê²½ë°ì´í„°.csv",
        "í•˜ëŠ˜ê³ ": "í•˜ëŠ˜ê³ _í™˜ê²½ë°ì´í„°.csv",
        "ì•„ë¼ê³ ": "ì•„ë¼ê³ _í™˜ê²½ë°ì´í„°.csv",
        "ë™ì‚°ê³ ": "ë™ì‚°ê³ _í™˜ê²½ë°ì´í„°.csv",
    }

    for school, desired_name in desired_files.items():
        p = find_file_by_name(data_dir, desired_name)
        if p is None:
            continue

        df = read_csv_safely(p)
        df = standardize_env_columns(df)
        df["í•™êµ"] = school
        env[school] = df

    return env


@st.cache_data(show_spinner=False)
def load_growth_data(data_dir: Path) -> tuple[pd.DataFrame, list[str], Path | None]:
    desired_name = "4ê°œêµ_ìƒìœ¡ê²°ê³¼ë°ì´í„°.xlsx"
    xlsx_path = find_file_by_name(data_dir, desired_name)

    # ì—…ë¡œë“œ í™˜ê²½ì—ì„œ í™•ì¥ìê°€ ì¤‘ë³µë˜ëŠ” ê²½ìš° ëŒ€ë¹„
    if xlsx_path is None:
        xlsx_path = find_file_by_name(data_dir, "4ê°œêµ_ìƒìœ¡ê²°ê³¼ë°ì´í„°.xlsx.xlsx")

    if xlsx_path is None:
        return pd.DataFrame(), [], None

    xls = pd.ExcelFile(xlsx_path)
    sheet_names = list(xls.sheet_names)  # âœ… ì‹œíŠ¸ëª… í•˜ë“œì½”ë”© ê¸ˆì§€

    frames = []
    for sh in sheet_names:
        df = pd.read_excel(xls, sheet_name=sh, engine="openpyxl")
        df["í•™êµ"] = sh
        frames.append(df)

    all_df = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()
    return all_df, sheet_names, xlsx_path


# =========================
# Summaries
# =========================
def env_summary(env_by_school: dict[str, pd.DataFrame]) -> pd.DataFrame:
    rows = []
    for school in SCHOOL_ORDER:
        df = env_by_school.get(school)
        if df is None or df.empty:
            continue
        row = {"í•™êµ": school}
        for col in ["temperature", "humidity", "ph", "ec"]:
            row[col] = pd.to_numeric(df.get(col, pd.Series(dtype=float)), errors="coerce").mean()
        rows.append(row)
    return pd.DataFrame(rows)


def growth_summary(growth_df: pd.DataFrame) -> pd.DataFrame:
    if growth_df is None or growth_df.empty:
        return pd.DataFrame()

    col_leaves = pick_col(growth_df, ["ì ìˆ˜(ì¥)", "ììˆ˜(ì¥)", "ì ìˆ˜", "ììˆ˜"])
    col_shoot = pick_col(growth_df, ["ì§€ìƒë¶€ ê¸¸ì´(mm)", "ì§€ìƒë¶€ê¸¸ì´(mm)", "ì§€ìƒë¶€ ê¸¸ì´", "ì§€ìƒë¶€ê¸¸ì´"])
    col_weight = pick_col(growth_df, ["ìƒì¤‘ëŸ‰(g)", "ìƒì¤‘ëŸ‰"])

    if col_weight is None:
        return pd.DataFrame()

    df = growth_df.copy()
    df[col_weight] = pd.to_numeric(df[col_weight], errors="coerce")
    if col_leaves is not None:
        df[col_leaves] = pd.to_numeric(df[col_leaves], errors="coerce")
    if col_shoot is not None:
        df[col_shoot] = pd.to_numeric(df[col_shoot], errors="coerce")

    grp = df.groupby("í•™êµ", dropna=False)
    rows = []
    for school in SCHOOL_ORDER:
        if school not in grp.groups:
            continue
        g = grp.get_group(school)
        rows.append(
            {
                "í•™êµ": school,
                "ê°œì²´ìˆ˜": int(g.shape[0]),
                "í‰ê· _ìƒì¤‘ëŸ‰": float(g[col_weight].mean()),
                "í‰ê· _ììˆ˜": float(g[col_leaves].mean()) if col_leaves else float("nan"),
                "í‰ê· _ì§€ìƒë¶€ê¸¸ì´": float(g[col_shoot].mean()) if col_shoot else float("nan"),
            }
        )
    return pd.DataFrame(rows)


def compute_optimal_ec_from_growth(gsum: pd.DataFrame) -> float | None:
    if gsum is None or gsum.empty or "í‰ê· _ìƒì¤‘ëŸ‰" not in gsum.columns:
        return None
    tmp = gsum.dropna(subset=["í‰ê· _ìƒì¤‘ëŸ‰"]).copy()
    if tmp.empty:
        return None
    best_school = tmp.sort_values("í‰ê· _ìƒì¤‘ëŸ‰", ascending=False).iloc[0]["í•™êµ"]
    return TARGET_EC_BY_SCHOOL.get(best_school)


# =========================
# UI
# =========================
st.title("ğŸŒ± ê·¹ì§€ì‹ë¬¼ ìµœì  EC ë†ë„ ì—°êµ¬")

data_dir = get_data_dir()

with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    school_option = st.selectbox("í•™êµ ì„ íƒ", ["ì „ì²´"] + SCHOOL_ORDER, index=0)

    # âœ… ë””ë²„ê·¸: data í´ë” ì‹¤ì œ ì¸ì‹ í™•ì¸
    with st.expander("ğŸ§ª ë””ë²„ê·¸: data í´ë”/íŒŒì¼ í™•ì¸"):
        st.write("data_dir =", str(data_dir))
        if data_dir.exists():
            st.write("files =", [p.name for p in data_dir.iterdir() if p.is_file()])
        else:
            st.error("data í´ë”ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")


with st.spinner("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
    env_by_school = load_environment_data(data_dir)
    growth_df, sheet_names, growth_path = load_growth_data(data_dir)

missing_env = [s for s in SCHOOL_ORDER if s not in env_by_school]
if missing_env:
    st.warning(f"í™˜ê²½ ë°ì´í„°ê°€ ì—†ëŠ” í•™êµ: {', '.join(missing_env)} (data/ í´ë” íŒŒì¼ëª… ë˜ëŠ” ì¸ì½”ë”©/ì»¬ëŸ¼ í™•ì¸)")

if growth_df is None or growth_df.empty:
    st.error("ìƒìœ¡ ê²°ê³¼ XLSX ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. data/ í´ë”ì— '4ê°œêµ_ìƒìœ¡ê²°ê³¼ë°ì´í„°.xlsx'ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

env_sum = env_summary(env_by_school)
grow_sum = growth_summary(growth_df)
optimal_ec_from_data = compute_optimal_ec_from_growth(grow_sum)

total_individuals = int(growth_df.shape[0])

env_concat = []
for s in SCHOOL_ORDER:
    df = env_by_school.get(s)
    if df is not None and not df.empty:
        env_concat.append(df)
env_all = pd.concat(env_concat, ignore_index=True) if env_concat else pd.DataFrame()
avg_temp = pd.to_numeric(env_all.get("temperature", pd.Series(dtype=float)), errors="coerce").mean() if not env_all.empty else float("nan")
avg_hum = pd.to_numeric(env_all.get("humidity", pd.Series(dtype=float)), errors="coerce").mean() if not env_all.empty else float("nan")

tab1, tab2, tab3 = st.tabs(["ğŸ“– ì‹¤í—˜ ê°œìš”", "ğŸŒ¡ï¸ í™˜ê²½ ë°ì´í„°", "ğŸ“Š ìƒìœ¡ ê²°ê³¼"])


# =========================
# Tab 1
# =========================
with tab1:
    st.subheader("ì—°êµ¬ ë°°ê²½ ë° ëª©ì ")
    st.write(
        """
ë³¸ ì—°êµ¬ëŠ” 4ê°œ í•™êµê°€ ì„œë¡œ ë‹¤ë¥¸ EC(ì–‘ì•¡ ì „ê¸°ì „ë„ë„) ì¡°ê±´ì—ì„œ ê·¹ì§€ì‹ë¬¼ì„ ì¬ë°°í•œ ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬,
**ìƒìœ¡ ì§€í‘œ(ìƒì¤‘ëŸ‰Â·ì ìˆ˜Â·ê¸¸ì´)**ê°€ ê°€ì¥ ìš°ìˆ˜í•œ **ìµœì  EC ë†ë„**ë¥¼ ë„ì¶œí•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

- í•™êµë³„ í™˜ê²½ ë°ì´í„°: ì˜¨ë„/ìŠµë„/pH/ECì˜ ì‹œê°„ ë³€í™” ë° í‰ê·  ë¹„êµ
- ìƒìœ¡ ê²°ê³¼ ë°ì´í„°: í•™êµ(=EC ì¡°ê±´)ë³„ ìƒìœ¡ ì„±ê³¼ ë¹„êµ ë° ìµœì  ì¡°ê±´ íŒë‹¨
"""
    )

    st.subheader("í•™êµë³„ EC ì¡°ê±´")
    rows = []
    for school in SCHOOL_ORDER:
        n = int((growth_df["í•™êµ"] == school).sum()) if "í•™êµ" in growth_df.columns else 0
        rows.append(
            {
                "í•™êµëª…": school,
                "EC ëª©í‘œ": TARGET_EC_BY_SCHOOL.get(school),
                "ê°œì²´ìˆ˜": n,
                "ìƒ‰ìƒ": COLOR_BY_SCHOOL.get(school),
            }
        )
    st.dataframe(pd.DataFrame(rows), use_container_width=True)

    st.subheader("ì£¼ìš” ì§€í‘œ")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ì´ ê°œì²´ìˆ˜", f"{total_individuals:,} ê°œì²´")
    c2.metric("í‰ê·  ì˜¨ë„", "-" if pd.isna(avg_temp) else f"{avg_temp:.2f} Â°C")
    c3.metric("í‰ê·  ìŠµë„", "-" if pd.isna(avg_hum) else f"{avg_hum:.2f} %")
    c4.metric("ìµœì  EC", f"{OPTIMAL_EC:.1f} (í•˜ëŠ˜ê³ )")


# =========================
# Tab 2
# =========================
with tab2:
    st.subheader("í•™êµë³„ í™˜ê²½ í‰ê·  ë¹„êµ")

    if env_sum is None or env_sum.empty:
        st.error("í™˜ê²½ ë°ì´í„° í‰ê· ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CSV ì»¬ëŸ¼(time, temperature, humidity, ph, ec)ì„ í™•ì¸í•˜ì„¸ìš”.")
    else:
        env_sum_plot = env_sum.copy()
        env_sum_plot["í•™êµ"] = pd.Categorical(env_sum_plot["í•™êµ"], categories=SCHOOL_ORDER, ordered=True)
        env_sum_plot = env_sum_plot.sort_values("í•™êµ")

        fig = make_subplots(
            rows=2,
            cols=2,
            subplot_titles=("í‰ê·  ì˜¨ë„", "í‰ê·  ìŠµë„", "í‰ê·  pH", "ëª©í‘œ EC vs ì‹¤ì¸¡ EC ë¹„êµ(í‰ê· )"),
        )

        fig.add_trace(go.Bar(x=env_sum_plot["í•™êµ"], y=env_sum_plot["temperature"], name="í‰ê·  ì˜¨ë„"), row=1, col=1)
        fig.add_trace(go.Bar(x=env_sum_plot["í•™êµ"], y=env_sum_plot["humidity"], name="í‰ê·  ìŠµë„"), row=1, col=2)
        fig.add_trace(go.Bar(x=env_sum_plot["í•™êµ"], y=env_sum_plot["ph"], name="í‰ê·  pH"), row=2, col=1)

        target_ec = [TARGET_EC_BY_SCHOOL.get(str(s), None) for s in env_sum_plot["í•™êµ"].astype(str)]
        fig.add_trace(go.Bar(x=env_sum_plot["í•™êµ"], y=target_ec, name="ëª©í‘œ EC"), row=2, col=2)
        fig.add_trace(go.Bar(x=env_sum_plot["í•™êµ"], y=env_sum_plot["ec"], name="ì‹¤ì¸¡ EC(í‰ê· )"), row=2, col=2)

        fig.update_layout(barmode="group", height=650, title="í•™êµë³„ í™˜ê²½ í‰ê· (ìš”ì•½)")
        fig = apply_plotly_korean_font(fig)
        st.plotly_chart(fig, use_container_width=True)

    st.divider()
    st.subheader("ì„ íƒí•œ í•™êµ ì‹œê³„ì—´")

    ts_frames = []
    for s in SCHOOL_ORDER:
        df = env_by_school.get(s)
        if df is None or df.empty:
            continue
        if "time" not in df.columns:
            continue
        tmp = df.copy()
        tmp["í•™êµ"] = s
        ts_frames.append(tmp)

    ts_all = pd.concat(ts_frames, ignore_index=True) if ts_frames else pd.DataFrame()

    if ts_all.empty:
        st.error("ì‹œê³„ì—´ ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ í™˜ê²½ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. CSVì— time ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    else:
        ts_all = ensure_datetime(ts_all, "time")
        ts_show = ts_all.copy() if school_option == "ì „ì²´" else ts_all[ts_all["í•™êµ"] == school_option].copy()

        for col in ["temperature", "humidity", "ec"]:
            if col in ts_show.columns:
                ts_show[col] = pd.to_numeric(ts_show[col], errors="coerce")

        if "temperature" in ts_show.columns:
            fig_t = px.line(ts_show, x="time", y="temperature",
                            color="í•™êµ" if school_option == "ì „ì²´" else None,
                            title="ì˜¨ë„ ë³€í™”(ì‹œê°„)")
            fig_t = apply_plotly_korean_font(fig_t)
            st.plotly_chart(fig_t, use_container_width=True)

        if "humidity" in ts_show.columns:
            fig_h = px.line(ts_show, x="time", y="humidity",
                            color="í•™êµ" if school_option == "ì „ì²´" else None,
                            title="ìŠµë„ ë³€í™”(ì‹œê°„)")
            fig_h = apply_plotly_korean_font(fig_h)
            st.plotly_chart(fig_h, use_container_width=True)

        if "ec" in ts_show.columns:
            fig_ec = px.line(ts_show, x="time", y="ec",
                             color="í•™êµ" if school_option == "ì „ì²´" else None,
                             title="EC ë³€í™”(ì‹œê°„) - ëª©í‘œ EC ê¸°ì¤€ì„  í¬í•¨")
            if school_option == "ì „ì²´":
                fig_ec.add_hline(y=OPTIMAL_EC, line_dash="dash", annotation_text="ìµœì  EC(2.0) ê¸°ì¤€ì„ ")
            else:
                t = TARGET_EC_BY_SCHOOL.get(school_option)
                if t is not None:
                    fig_ec.add_hline(y=t, line_dash="dash", annotation_text=f"ëª©í‘œ EC({t})")
            fig_ec = apply_plotly_korean_font(fig_ec)
            st.plotly_chart(fig_ec, use_container_width=True)

        with st.expander("ğŸ“„ í™˜ê²½ ë°ì´í„° ì›ë³¸ í…Œì´ë¸” + CSV ë‹¤ìš´ë¡œë“œ"):
            st.dataframe(ts_show, use_container_width=True)
            csv_bytes = ts_show.to_csv(index=False).encode("utf-8-sig")
            st.download_button("â¬‡ï¸ CSV ë‹¤ìš´ë¡œë“œ", data=csv_bytes, file_name="í™˜ê²½ë°ì´í„°_ì›ë³¸.csv", mime="text/csv")


# =========================
# Tab 3
# =========================
with tab3:
    st.subheader("ğŸ¥‡ í•µì‹¬ ê²°ê³¼")

    col_weight = pick_col(growth_df, ["ìƒì¤‘ëŸ‰(g)", "ìƒì¤‘ëŸ‰"])
    col_leaves = pick_col(growth_df, ["ì ìˆ˜(ì¥)", "ììˆ˜(ì¥)", "ì ìˆ˜", "ììˆ˜"])
    col_shoot = pick_col(growth_df, ["ì§€ìƒë¶€ ê¸¸ì´(mm)", "ì§€ìƒë¶€ê¸¸ì´(mm)", "ì§€ìƒë¶€ ê¸¸ì´", "ì§€ìƒë¶€ê¸¸ì´"])

    if col_weight is None:
        st.error("ìƒìœ¡ ë°ì´í„°ì—ì„œ ìƒì¤‘ëŸ‰ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì»¬ëŸ¼ëª…ì„ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

    if grow_sum is not None and not grow_sum.empty:
        best_row = grow_sum.dropna(subset=["í‰ê· _ìƒì¤‘ëŸ‰"]).sort_values("í‰ê· _ìƒì¤‘ëŸ‰", ascending=False).head(1)
        if not best_row.empty:
            best_school = best_row.iloc[0]["í•™êµ"]
            best_ec = TARGET_EC_BY_SCHOOL.get(best_school)
            best_w = best_row.iloc[0]["í‰ê· _ìƒì¤‘ëŸ‰"]

            a, b, c = st.columns([1.2, 1.2, 2])
            a.metric("ë°ì´í„° ê¸°ì¤€ í‰ê·  ìƒì¤‘ëŸ‰ ìµœëŒ“ê°’", f"{best_w:.3f} g", f"{best_school} (EC {best_ec})")
            b.metric("ìµœì  EC (ì—°êµ¬ ê²°ë¡ )", f"{OPTIMAL_EC:.1f}", "í•˜ëŠ˜ê³ (EC 2.0) ìµœì ")
            c.info("â€» ìµœì  ECëŠ” ì—°êµ¬ ì„¤ê³„ìƒ **í•˜ëŠ˜ê³ (EC 2.0)** ë¥¼ ìµœì  ì¡°ê±´ìœ¼ë¡œ ê²°ë¡  ë‚´ë¦½ë‹ˆë‹¤.")

    st.divider()
    st.subheader("ECë³„ ìƒìœ¡ ë¹„êµ (2x2)")

    gsum_plot = grow_sum.copy() if grow_sum is not None else pd.DataFrame()
    if not gsum_plot.empty:
        if school_option != "ì „ì²´":
            gsum_plot = gsum_plot[gsum_plot["í•™êµ"] == school_option]
        gsum_plot["í•™êµ"] = pd.Categorical(gsum_plot["í•™êµ"], categories=SCHOOL_ORDER, ordered=True)
        gsum_plot = gsum_plot.sort_values("í•™êµ")

        fig2 = make_subplots(
            rows=2,
            cols=2,
            subplot_titles=("í‰ê·  ìƒì¤‘ëŸ‰ (â­ ê°€ì¥ ì¤‘ìš”)", "í‰ê·  ì ìˆ˜", "í‰ê·  ì§€ìƒë¶€ ê¸¸ì´(mm)", "ê°œì²´ìˆ˜ ë¹„êµ"),
        )
        fig2.add_trace(go.Bar(x=gsum_plot["í•™êµ"], y=gsum_plot["í‰ê· _ìƒì¤‘ëŸ‰"], name="í‰ê·  ìƒì¤‘ëŸ‰"), row=1, col=1)
        fig2.add_trace(go.Bar(x=gsum_plot["í•™êµ"], y=gsum_plot["í‰ê· _ììˆ˜"], name="í‰ê·  ì ìˆ˜"), row=1, col=2)
        fig2.add_trace(go.Bar(x=gsum_plot["í•™êµ"], y=gsum_plot["í‰ê· _ì§€ìƒë¶€ê¸¸ì´"], name="í‰ê·  ì§€ìƒë¶€ ê¸¸ì´"), row=2, col=1)
        fig2.add_trace(go.Bar(x=gsum_plot["í•™êµ"], y=gsum_plot["ê°œì²´ìˆ˜"], name="ê°œì²´ìˆ˜"), row=2, col=2)

        fig2.update_layout(barmode="group", height=650, title="í•™êµ(=EC ì¡°ê±´)ë³„ ìƒìœ¡ ë¹„êµ")
        fig2 = apply_plotly_korean_font(fig2)
        st.plotly_chart(fig2, use_container_width=True)

    st.divider()
    st.subheader("í•™êµë³„ ìƒì¤‘ëŸ‰ ë¶„í¬")

    gdf = growth_df.copy()
    gdf[col_weight] = pd.to_numeric(gdf[col_weight], errors="coerce")
    if col_leaves is not None:
        gdf[col_leaves] = pd.to_numeric(gdf[col_leaves], errors="coerce")
    if col_shoot is not None:
        gdf[col_shoot] = pd.to_numeric(gdf[col_shoot], errors="coerce")
    if school_option != "ì „ì²´":
        gdf = gdf[gdf["í•™êµ"] == school_option].copy()

    fig_box = px.violin(
        gdf.dropna(subset=[col_weight]),
        x="í•™êµ",
        y=col_weight,
        box=True,
        points="all",
        title="ìƒì¤‘ëŸ‰ ë¶„í¬(ë°”ì´ì˜¬ë¦° + ë°•ìŠ¤)",
    )
    fig_box = apply_plotly_korean_font(fig_box)
    st.plotly_chart(fig_box, use_container_width=True)

    st.divider()
    st.subheader("ìƒê´€ê´€ê³„ ë¶„ì„ (ì‚°ì ë„ 2ê°œ)")

    left, right = st.columns(2)

    with left:
        if col_leaves is None:
            st.warning("ì ìˆ˜ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í•´ 'ì ìˆ˜ vs ìƒì¤‘ëŸ‰' ì‚°ì ë„ë¥¼ ìƒëµí•©ë‹ˆë‹¤.")
        else:
            fig_sc1 = px.scatter(
                gdf.dropna(subset=[col_leaves, col_weight]),
                x=col_leaves,
                y=col_weight,
                color="í•™êµ" if school_option == "ì „ì²´" else None,
                title="ì ìˆ˜ vs ìƒì¤‘ëŸ‰",
                labels={col_leaves: "ì ìˆ˜(ì¥)", col_weight: "ìƒì¤‘ëŸ‰(g)"},
            )
            fig_sc1 = apply_plotly_korean_font(fig_sc1)
            st.plotly_chart(fig_sc1, use_container_width=True)

    with right:
        if col_shoot is None:
            st.warning("ì§€ìƒë¶€ ê¸¸ì´ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í•´ 'ì§€ìƒë¶€ ê¸¸ì´ vs ìƒì¤‘ëŸ‰' ì‚°ì ë„ë¥¼ ìƒëµí•©ë‹ˆë‹¤.")
        else:
            fig_sc2 = px.scatter(
                gdf.dropna(subset=[col_shoot, col_weight]),
                x=col_shoot,
                y=col_weight,
                color="í•™êµ" if school_option == "ì „ì²´" else None,
                title="ì§€ìƒë¶€ ê¸¸ì´ vs ìƒì¤‘ëŸ‰",
                labels={col_shoot: "ì§€ìƒë¶€ ê¸¸ì´(mm)", col_weight: "ìƒì¤‘ëŸ‰(g)"},
            )
            fig_sc2 = apply_plotly_korean_font(fig_sc2)
            st.plotly_chart(fig_sc2, use_container_width=True)

    with st.expander("ğŸ“„ í•™êµë³„ ìƒìœ¡ ë°ì´í„° ì›ë³¸ + XLSX ë‹¤ìš´ë¡œë“œ"):
        st.dataframe(gdf, use_container_width=True)

        buffer = io.BytesIO()
        gdf.to_excel(buffer, index=False, engine="openpyxl")
        buffer.seek(0)

        st.download_button(
            label="â¬‡ï¸ XLSX ë‹¤ìš´ë¡œë“œ",
            data=buffer,
            file_name="ìƒìœ¡ë°ì´í„°_ì›ë³¸.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

st.caption("Â© Polar Plant EC Dashboard â€” Streamlit / Plotly")
